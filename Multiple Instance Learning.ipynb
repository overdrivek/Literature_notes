{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mutiple Instace Learning: \n",
    "* MIL is a form of weakly supervised learning where the training instances are arranged in sets, called bags, and a label is provided for the entire bag.[1]\n",
    "\n",
    "According to [1], the four MIL Problem characiteristics are \n",
    "1. Composition of the bags, \n",
    "2. types of data distribution, \n",
    "3. ambiguity of instance labels and \n",
    "4. task to be performed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Instance Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Assumptions*: \n",
    "Standard MIL assumption: All negative bags contain only negative instances and the that positive bags contain at least one positive instance. The positive instances are called witnesses. \n",
    "\n",
    "Collective MIL assumption: More than one instance label is required to define the bag label. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Tasks*\n",
    "* Classification: Instance level vs Bag level. \n",
    "* Regression\n",
    "* Ranking: rank bags or instances instead of assigning a class label or score. \n",
    "* Clustering: Finding clusters or a structure among a set of unlabeled bags. Clustering in bag space done using standard algorithms and set-based distance measures such as *k*-Medoids and the Hausdorff distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Literature Review: \n",
    "\n",
    "[2] distringuished two types of ambiguity in MIL problems. The first type is *polymorphism* ambiguity, in which each instance is a distinct entity or a distinct version of an entity (e.g. conformations of a molecule). The second is *part-whole* ambiguity in which all the instances are part of the same object (e.g. segments of an image).\n",
    "\n",
    "[4] compared methods for generating bags of instances from images. They found that the sampling instances densely leads to a higher accuracy than sampling instances at interest points or after segmentation. They also found that methods using the collective assumption performed better for image classification.\n",
    "\n",
    "When the number of bags is low, it is preferable to use an instance-based method. [5]\n",
    "\n",
    "Performance of MIL is only mildly dependent on the number of instances per bag [6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Witness Rate\n",
    "The witness rate (WR) is the proportion of positive instances in positive bags. When the WR is very high, positive bags contain only a few negative instances. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Multiple Instance Learning for Image Classiﬁcation and Auto-Annotation [7]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](MIL_architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features from all the individual instances of the bag are aggregated using max pooling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note\n",
    "For AOI: \n",
    "A bag should be labeled positive if and only if all the instances of the bag are positive. \n",
    "A bag should be labeled negative if, few to some instances are already negative. \n",
    "This is a different situation to the standard assumption, where the presence of just one positive instance is enough to classify the bag as positive and all the instances of a bag must be negative for the bag to be labeled negative. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References: \n",
    "1. Multiple Instance Learning: A Surve3y of Problem Characteristics and Applications https://arxiv.org/abs/1612.03365 \n",
    "2. B. Babenko, “Multiple Instance Learning : Algorithms and Applications,” University of California, San Diego, USA, Tech. Rep., 2008.\n",
    "3.  F. Herrera, S. Ventura, R. Bello, C. Cornelis, A. Zafra, D. S´anchez-Tarrag´o, and S. Vluymans,\n",
    "Multiple Instance Learning: Foundation and Algorithms. Springer, 2016.\n",
    "4. X.-S. Wei and Z.-H. Zhou, “An empirical study on image bag generators for multi-instance\n",
    "learning,” Machine Learning, pp. 1–44, 2016.\n",
    "5. E. Alpaydın, V. Cheplygina, M. Loog, and D. M. Tax, “Single- vs. multiple-instance classiﬁ-\n",
    "cation,” Pattern Recognit., vol. 48, no. 9, pp. 2831–2838, Sep 2015.\n",
    "6. S. Sabato and N. Tishby, “Multi-instance Learning with Any Hypothesis Class,” J. Mach.\n",
    "Learn. Res., vol. 13, no. 1, pp. 2999–3039, Oct 2012.\n",
    "7. J. Wu, Yinan Yu, Chang Huang and Kai Yu, \"Deep multiple instance learning for image classification and auto-annotation,\" 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Boston, MA, 2015, pp. 3460-3469."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
